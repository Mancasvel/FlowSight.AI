# FlowSight AI - Inicio R√°pido con IA

## üöÄ Setup en 5 Minutos

### Opci√≥n 1: Usar Modelos Locales (Recomendado - Gratis y Privado)

```bash
# 1. Instala Ollama
# Visita: https://ollama.ai/download
# Descarga e instala para tu sistema operativo

# 2. Inicia Ollama
ollama serve

# 3. Descarga el modelo Phi-3
ollama pull phi3:3.8b

# ¬°Listo! La IA local ya est√° funcionando
```

### Opci√≥n 2: Usar OpenRouter (Cloud - Pago)

```bash
# 1. Visita https://openrouter.ai/keys
# 2. Crea una cuenta gratuita
# 3. Click en "Create Key"
# 4. Copia tu API key (empieza con sk-or-v1-...)

# 2. Agrega a tu Configuraci√≥n
cd apps/dashboard
echo "OPENROUTER_API_KEY=sk-or-v1-tu-key-aqui" >> .env.local
echo "DEFAULT_AI_MODEL=openai/gpt-4-turbo-preview" >> .env.local
```

### 3. Instala Dependencia

```bash
pnpm install
```

### 4. Reinicia el Dashboard

```bash
pnpm dev
```

¬°Listo! La IA ya est√° activa. üéâ

---

## üß™ Probar la IA

### Opci√≥n 1: Autom√°tico (Reglas Engine)

La IA se ejecutar√° autom√°ticamente cada ~10 eventos que recibas del agent, usando modelos locales por defecto:

```bash
# 1. Aseg√∫rate de que Ollama est√© corriendo
ollama serve

# 2. Inicia el agent
cd apps/agent
pnpm dev

# 3. Simula varios eventos
# En el agent, click en "üíª Coding" varias veces

# 4. Mira los logs del dashboard
# Ver√°s: "AI Blocker Analysis Result: {...}" (usando Phi-3 local)
```

### Opci√≥n 2: Manual (API)

```bash
# Analiza la actividad de un developer
curl -X POST http://localhost:3000/api/ai/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "devId": "tu@email.com",
    "analysisType": "blocker",
    "timeRange": {
      "start": "2025-10-24T08:00:00Z",
      "end": "2025-10-24T16:00:00Z"
    }
  }'
```

**Respuesta Ejemplo:**
```json
{
  "success": true,
  "analysis": {
    "isBlocked": true,
    "confidence": 87,
    "reason": "El desarrollador ha estado buscando el mismo error en StackOverflow por 45 minutos sin progreso en el c√≥digo",
    "category": "technical",
    "suggestions": [
      "Revisar los logs del servidor para obtener m√°s contexto sobre el error",
      "Hacer pair programming con un senior developer",
      "Verificar si hay problemas conocidos en la documentaci√≥n del framework"
    ],
    "estimatedImpact": "high"
  },
  "metadata": {
    "eventsAnalyzed": 45,
    "timeRange": {
      "start": "2025-10-24T08:00:00Z",
      "end": "2025-10-24T16:00:00Z"
    }
  }
}
```

### Opci√≥n 3: Verificar Estado

```bash
curl http://localhost:3000/api/ai/analyze/status
```

**Respuesta:**
```json
{
  "available": true,
  "providers": {
    "openrouter": true,
    "openai": false
  },
  "models": {
    "default": "openai/gpt-4-turbo-preview"
  }
}
```

---

## üí° Casos de Uso

### 1. Detectar Desarrolladores Bloqueados

**Problema:** No sabes cu√°ndo un developer est√° atorado hasta que te lo dice (a veces d√≠as despu√©s)

**Soluci√≥n:** La IA analiza patrones y te alerta proactivamente

```typescript
// Autom√°tico via Rules Engine
// Si confidence > 70%, el ticket se marca como "blocked"
// El PM recibe notificaci√≥n en tiempo real
```

### 2. An√°lisis de Productividad

**Problema:** Quieres entender si el equipo tiene suficiente tiempo de "deep work"

**Soluci√≥n:** La IA identifica per√≠odos de concentraci√≥n y distracciones

```bash
curl -X POST http://localhost:3000/api/ai/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "devId": "dev@company.com",
    "analysisType": "productivity"
  }'
```

**Resultado:**
```json
{
  "focusScore": 78,
  "deepWorkPeriods": [
    {"start": "09:00", "end": "10:45", "duration": 105}
  ],
  "insights": [
    "Developer tuvo 2 per√≠odos de deep work > 1 hora",
    "Productividad m√°xima entre 9-11am",
    "Sugerencia: Bloquear calendario en estas horas"
  ]
}
```

### 3. Estimaci√≥n Inteligente de Tickets

**Problema:** No sabes cu√°nto falta realmente para completar un ticket

**Soluci√≥n:** La IA analiza el progreso y estima tiempo restante

```bash
curl -X POST http://localhost:3000/api/ai/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "ticketId": "FE-123",
    "analysisType": "ticket"
  }'
```

**Resultado:**
```json
{
  "estimatedCompletion": 65,
  "velocity": "normal",
  "timeEstimate": {
    "remaining": 4,
    "confidence": 75
  },
  "risks": [
    "Baja actividad de commits en los √∫ltimos 2 d√≠as"
  ],
  "nextActions": [
    "Hacer commit del trabajo actual",
    "Actualizar tests"
  ]
}
```

---

## üí∞ Costos

### Opci√≥n 1: Modelos Locales - ¬°GRATIS! üéâ

**Phi-3 3.8B via Ollama:**
- **Costo mensual:** $0 USD
- **Hardware:** Tu propia m√°quina
- **Privacidad:** 100% local
- **Velocidad:** Sub-200ms (despu√©s de carga inicial)

**Ventajas:**
- ‚úÖ Completamente gratis
- ‚úÖ M√°xima privacidad
- ‚úÖ Sin l√≠mites de uso
- ‚úÖ Funciona offline
- ‚úÖ Control total

### Opci√≥n 2: Modelos Cloud (Pago)

#### Modelo Recomendado: Claude 3 Sonnet

**50 developers, 22 d√≠as/mes:**
- **Costo mensual:** ~$85 USD
- **Por developer:** $1.70/mes
- **Por d√≠a:** $3.86

**¬øPor qu√© Claude 3 Sonnet?**
- ‚úÖ Excelente calidad de an√°lisis
- ‚úÖ Precio razonable
- ‚úÖ Respuestas r√°pidas
- ‚úÖ Buen balance costo/beneficio

#### Alternativa Econ√≥mica: Claude 3 Haiku

**50 developers, 22 d√≠as/mes:**
- **Costo mensual:** ~$7 USD
- **Por developer:** $0.14/mes
- **Por d√≠a:** $0.32

**Trade-off:**
- ‚úÖ S√∫per econ√≥mico
- ‚ö†Ô∏è An√°lisis menos detallados
- ‚úÖ Suficiente para detecci√≥n b√°sica

### Cambiar Modelo

```bash
# En .env.local
DEFAULT_AI_MODEL=anthropic/claude-3-sonnet  # Recomendado
# o
DEFAULT_AI_MODEL=anthropic/claude-3-haiku   # Econ√≥mico
# o
DEFAULT_AI_MODEL=openai/gpt-4-turbo-preview  # Premium
```

---

## üè¢ Para Empresas: Usar Modelo Propio

### Opci√≥n 1: OpenAI Direct (Si ya tienes cuenta)

```bash
# .env.local
OPENAI_API_KEY=sk-tu-key-de-openai
DEFAULT_AI_MODEL=gpt-4-turbo-preview
```

### Opci√≥n 2: Modelo Custom (On-Premise)

```typescript
// Via API
POST /api/projects/default/ai-config
{
  "provider": "custom",
  "apiKey": "tu-key-interno",
  "model": "llama-3-70b-fine-tuned",
  "baseURL": "https://ai.tuempresa.com/v1"
}
```

**Ventajas:**
- ‚úÖ M√°xima privacidad
- ‚úÖ Sin costos por uso
- ‚úÖ Control total
- ‚úÖ Cumplimiento regulatorio

**Ejemplo con vLLM:**
```bash
# Deploy en tu servidor
docker run --gpus all -p 8000:8000 \
  vllm/vllm-openai:latest \
  --model meta-llama/Llama-3-70b-chat-hf \
  --api-key tu-key-interno

# Configura FlowSight
curl -X PUT http://localhost:3000/api/projects/default/ai-config \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "custom",
    "apiKey": "tu-key-interno",
    "model": "meta-llama/Llama-3-70b-chat-hf",
    "baseURL": "http://tu-servidor:8000/v1"
  }'
```

---

## üîß Troubleshooting

### "AI analysis failed: Invalid API key"

```bash
# Verifica tu API key
echo $OPENROUTER_API_KEY

# Debe empezar con sk-or-v1-
# Si no, regenera en https://openrouter.ai/keys
```

### "Analysis not running"

```bash
# 1. Verifica que la variable est√° cargada
curl http://localhost:3000/api/ai/analyze/status

# 2. Si available:false, revisa .env.local
cat apps/dashboard/.env.local | grep OPENROUTER

# 3. Reinicia el dashboard
cd apps/dashboard
pnpm dev
```

### "Rate limit exceeded" (solo para OpenRouter)

```bash
# Opci√≥n 1: Reducir frecuencia de an√°lisis
# En apps/dashboard/src/lib/rules-engine.ts
# Cambiar: Math.random() < 0.1  ‚Üí  Math.random() < 0.05

# Opci√≥n 2: Usar modelo m√°s barato
# En .env.local
DEFAULT_AI_MODEL=anthropic/claude-3-haiku

# Opci√≥n 3: Agregar cr√©ditos en OpenRouter
# https://openrouter.ai/credits
```

### "Ollama connection failed"

```bash
# Verificar que Ollama est√© corriendo
ollama list

# Si no est√° corriendo, iniciarlo
ollama serve

# Verificar que el modelo est√© descargado
ollama pull phi3:3.8b

# Verificar que el puerto est√© abierto
curl http://localhost:11434/api/tags
```

### "Local AI analysis failed"

```bash
# Verificar configuraci√≥n
cd apps/dashboard
cat .env.local | grep -E "(OLLAMA|OPENROUTER)"

# Si no hay OPENROUTER_API_KEY, deber√≠a usar Ollama autom√°ticamente
# Verificar logs del dashboard para m√°s detalles
```

---

## üìö M√°s Informaci√≥n

- **Documentaci√≥n Completa:** Ver `AI_INTEGRATION.md`
- **API Reference:** Ver endpoints en el archivo
- **Modelos Disponibles:** https://openrouter.ai/models
- **Precios:** https://openrouter.ai/models (columna "Pricing")

---

## ‚úÖ Checklist - Modelos Locales

- [ ] Ollama instalado y corriendo (`ollama serve`)
- [ ] Modelo Phi-3 descargado (`ollama pull phi3:3.8b`)
- [ ] Dashboard corriendo en http://localhost:3000
- [ ] Agent configurado y enviando eventos
- [ ] Logs muestran "AI Blocker Analysis Result" (con Phi-3 local)

**¬°Todo listo con IA local!** üéâ

Ahora cada ~10 eventos, Phi-3 analizar√° autom√°ticamente la actividad y te alertar√° si detecta problemas.

## ‚úÖ Checklist - OpenRouter (Opcional)

- [ ] Cuenta en OpenRouter creada
- [ ] API key generada
- [ ] Variable `OPENROUTER_API_KEY` en `.env.local`
- [ ] Dashboard reiniciado
- [ ] API status retorna `available: true`
- [ ] Agent enviando eventos
- [ ] Logs muestran "AI Blocker Analysis Result" (con modelo cloud)

---

**Siguiente Paso:** Lee `AI_INTEGRATION.md` para configuraci√≥n avanzada y uso enterprise.




